{
  "models": {
    "qwen2.5:7b": {
      "temperature": 0.1,
      "max_tokens": 2048,
      "timeout": 300
    },
    "qwen2.5:14b": {
      "temperature": 0.1,
      "max_tokens": 2048,
      "timeout": 300
    },
    "qwen2.5:32b": {
      "temperature": 0.1,
      "max_tokens": 2048,
      "timeout": 300
    },
    "llama3:8b": {
      "temperature": 0.1,
      "max_tokens": 2048,
      "timeout": 300
    },
    "llama3:70b": {
      "temperature": 0.1,
      "max_tokens": 2048,
      "timeout": 300
    }
  },
  "representations": {
    "deontic": {
      "description": "Deontic logic representation"
    },
    "deontic_ai": {
      "description": "AI-generated deontic logic representation"
    }
  }
}
